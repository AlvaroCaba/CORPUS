{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecoazul/alvaro/CORPUS/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils_corpus import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 1.  Listado de adjetivos en el texto con conteo y frecuencia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraccion de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando PDFs: 100%|██████████| 53/53 [00:35<00:00,  1.51it/s]\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"/home/ecoazul/alvaro/CORPUS/data/input/corpus\"\n",
    "output_folder = \"/home/ecoazul/alvaro/CORPUS/data/output/question1/1.frases\"\n",
    "\n",
    "split_sentences_dict = {}\n",
    "\n",
    "for filename in tqdm(os.listdir(input_folder), desc=\"Procesando PDFs\"):\n",
    "    if filename.lower().endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(input_folder, filename)\n",
    "        extracted_text = extract_pdf_text(pdf_path)\n",
    "        cleaned_text = clean_text(extracted_text)\n",
    "        output_path = os.path.join(\n",
    "            output_folder,\n",
    "            f\"frases_{os.path.splitext(filename)[0]}.txt\"\n",
    "        )\n",
    "        split_sentences = save_sentences_to_file(cleaned_text, output_path)\n",
    "        split_sentences_dict[filename] = split_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodo Diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se encontró diccionario para el idioma: po en /home/ecoazul/alvaro/CORPUS/data/output/question1/1.frases/frases_05_PO_Naturaleza.txt\n",
      "No se encontró diccionario para el idioma: jp en /home/ecoazul/alvaro/CORPUS/data/output/question1/1.frases/frases_03_JP_Verde.txt\n",
      "No se encontró diccionario para el idioma: zh en /home/ecoazul/alvaro/CORPUS/data/output/question1/1.frases/frases_02_ZH_Tren.txt\n",
      "No se encontró diccionario para el idioma: jp en /home/ecoazul/alvaro/CORPUS/data/output/question1/1.frases/frases_05_JP_Naturaleza.txt\n",
      "No se encontró diccionario para el idioma: zh en /home/ecoazul/alvaro/CORPUS/data/output/question1/1.frases/frases_05_ZH_Naturaleza.txt\n",
      "No se encontró diccionario para el idioma: ko en /home/ecoazul/alvaro/CORPUS/data/output/question1/1.frases/frases_03_KO_Verde.txt\n",
      "No se encontró diccionario para el idioma: zh en /home/ecoazul/alvaro/CORPUS/data/output/question1/1.frases/frases_03_ZH_Verde.txt\n",
      "No se encontró diccionario para el idioma: jp en /home/ecoazul/alvaro/CORPUS/data/output/question1/1.frases/frases_02_JP_Tren.txt\n",
      "No se encontró diccionario para el idioma: nl en /home/ecoazul/alvaro/CORPUS/data/output/question1/1.frases/frases_03_NL_Verde.txt\n",
      "No se encontró diccionario para el idioma: nl en /home/ecoazul/alvaro/CORPUS/data/output/question1/1.frases/frases_01_NL_Cicloturismo.txt\n",
      "No se encontró diccionario para el idioma: po en /home/ecoazul/alvaro/CORPUS/data/output/question1/1.frases/frases_01_PO_Cicloturismo.txt\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "dic_folder = \"/home/ecoazul/alvaro/CORPUS/data/input/dic\"\n",
    "# Obtener todos los archivos de frases\n",
    "frases_folder = \"/home/ecoazul/alvaro/CORPUS/data/output/question1/1.frases\"\n",
    "frases_files = glob(os.path.join(frases_folder, \"frases_*.txt\"))\n",
    "output_folder = \"/home/ecoazul/alvaro/CORPUS/data/output/question1/2.Adjetivos diccionario\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "resultados = {}\n",
    "\n",
    "for frases_path in frases_files:\n",
    "    # Extraer el idioma del nombre del archivo (ejemplo: frases_01_ES_Cicloturismo.txt -> es)\n",
    "    partes = os.path.basename(frases_path).split(\"_\")\n",
    "    if len(partes) >= 3:\n",
    "        idioma = partes[2].lower()\n",
    "        dic_path = os.path.join(dic_folder, f\"{idioma}.adj\")\n",
    "        if os.path.exists(dic_path):\n",
    "            # Cargar diccionario de adjetivos\n",
    "            adjectives_map = load_adjective_dictionary(dic_path)\n",
    "            # Leer frases\n",
    "            with open(frases_path, encoding=\"utf-8\") as f:\n",
    "                split_sentences = [line.strip() for line in f if line.strip()]\n",
    "            # Extraer adjetivos\n",
    "            df_adjectives = extract_adjectives_from_text(split_sentences, adjectives_map)\n",
    "            resultados[frases_path] = df_adjectives\n",
    "            # Guardar el DataFrame de adjetivos en un CSV\n",
    "            csv_output = output_folder + \"/\" + os.path.basename(frases_path).replace(\".txt\", \"_adjetivos.csv\")\n",
    "            df_adjectives.to_csv(csv_output, index=False, encoding=\"utf-8\", sep=\";\")\n",
    "        else:\n",
    "            print(f\"No se encontró diccionario para el idioma: {idioma} en {frases_path}\")\n",
    "    else:\n",
    "        print(f\"Nombre de archivo inesperado: {frases_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frecuency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] frases_02_FR_Tren_adj_freq.csv generado con 198 adjetivos (total 5289 palabras)\n",
      "[✓] frases_02_EN_Tren_adj_freq.csv generado con 210 adjetivos (total 5144 palabras)\n",
      "[✓] frases_07_FR_Turismo sostenible_adj_freq.csv generado con 263 adjetivos (total 6069 palabras)\n",
      "[✓] frases_01_ES_Cicloturismo_adj_freq.csv generado con 258 adjetivos (total 5834 palabras)\n",
      "[✓] frases_04_ES_Gran Ruta Verde_adj_freq.csv generado con 459 adjetivos (total 13898 palabras)\n",
      "[✓] frases_03_IT_Verde_adj_freq.csv generado con 314 adjetivos (total 5313 palabras)\n",
      "[✓] frases_08_EN_Turismo rural_adj_freq.csv generado con 249 adjetivos (total 6901 palabras)\n",
      "[✓] frases_01_FR_Cicloturismo_adj_freq.csv generado con 199 adjetivos (total 6388 palabras)\n",
      "[✓] frases_02_IT_Tren_adj_freq.csv generado con 290 adjetivos (total 4950 palabras)\n",
      "[✓] frases_02_RU_Tren_adj_freq.csv generado con 0 adjetivos (total 209 palabras)\n",
      "[✓] frases_04_EN_Gran Ruta Verde_adj_freq.csv generado con 365 adjetivos (total 14409 palabras)\n",
      "[✓] frases_06_ES_Observación Naturaleza_adj_freq.csv generado con 270 adjetivos (total 5313 palabras)\n",
      "[✓] frases_02_ES_Tren_adj_freq.csv generado con 249 adjetivos (total 5256 palabras)\n",
      "[✓] frases_01_DE_Cicloturismo_adj_freq.csv generado con 246 adjetivos (total 6243 palabras)\n",
      "[✓] frases_08_ES_Turismo rural_adj_freq.csv generado con 336 adjetivos (total 7026 palabras)\n",
      "[✓] frases_03_ES_Verde_adj_freq.csv generado con 240 adjetivos (total 5487 palabras)\n",
      "[✓] frases_08_FR_Turismo rural_adj_freq.csv generado con 266 adjetivos (total 7492 palabras)\n",
      "[✓] frases_05_DE_Naturaleza_adj_freq.csv generado con 221 adjetivos (total 5675 palabras)\n",
      "[✓] frases_04_FR_Gran Ruta Verde_adj_freq.csv generado con 353 adjetivos (total 15220 palabras)\n",
      "[✓] frases_03_EN_Verde_adj_freq.csv generado con 239 adjetivos (total 5648 palabras)\n",
      "[✓] frases_01_PT_Cicloturismo_adj_freq.csv generado con 305 adjetivos (total 5946 palabras)\n",
      "[✓] frases_02_PT_Tren_adj_freq.csv generado con 280 adjetivos (total 5116 palabras)\n",
      "[✓] frases_04_PT_Gran Ruta Verde_adj_freq.csv generado con 523 adjetivos (total 14127 palabras)\n",
      "[✓] frases_07_EN_Turismo sostenible_adj_freq.csv generado con 231 adjetivos (total 5544 palabras)\n",
      "[✓] frases_05_RU_Naturaleza_adj_freq.csv generado con 0 adjetivos (total 101 palabras)\n",
      "[✓] frases_03_RU_Verde_adj_freq.csv generado con 0 adjetivos (total 108 palabras)\n",
      "[✓] frases_04_IT_Gran Ruta Verde_adj_freq.csv generado con 534 adjetivos (total 14136 palabras)\n",
      "[✓] frases_03_DE_Verde_adj_freq.csv generado con 225 adjetivos (total 5456 palabras)\n",
      "[✓] frases_03_PT_Verde_adj_freq.csv generado con 279 adjetivos (total 5491 palabras)\n",
      "[✓] frases_07_DE_Turismo sostenible_adj_freq.csv generado con 257 adjetivos (total 5818 palabras)\n",
      "[✓] frases_02_DE_Tren_adj_freq.csv generado con 251 adjetivos (total 5781 palabras)\n",
      "[✓] frases_05_FR_Naturaleza_adj_freq.csv generado con 240 adjetivos (total 6297 palabras)\n",
      "[✓] frases_07_ES_Turismo sostenible_adj_freq.csv generado con 292 adjetivos (total 5784 palabras)\n",
      "[✓] frases_05_EN_Naturaleza_adj_freq.csv generado con 237 adjetivos (total 5949 palabras)\n",
      "[✓] frases_03_FR_Verde_adj_freq.csv generado con 213 adjetivos (total 5891 palabras)\n",
      "[✓] frases_05_ES_Naturaleza_adj_freq.csv generado con 299 adjetivos (total 5907 palabras)\n",
      "[✓] frases_04_DE_Gran Ruta Verde_adj_freq.csv generado con 457 adjetivos (total 14454 palabras)\n",
      "[✓] frases_08_DE_Turismo rural_adj_freq.csv generado con 270 adjetivos (total 7732 palabras)\n",
      "[✓] frases_01_IT_Cicloturismo_adj_freq.csv generado con 260 adjetivos (total 5837 palabras)\n",
      "[✓] frases_06_EN_Observación Naturaleza_adj_freq.csv generado con 212 adjetivos (total 5054 palabras)\n",
      "[✓] frases_05_PT_Naturaleza_adj_freq.csv generado con 337 adjetivos (total 5871 palabras)\n",
      "[✓] frases_01_EN_Cicloturismo_adj_freq.csv generado con 231 adjetivos (total 6334 palabras)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Procesa TODOS los pares CSV/TXT de las carpetas:\n",
    "    2.Adjetivos diccionario   (CSV con _adjetivos.csv)\n",
    "    1.frases copy             (TXT completo)\n",
    "\n",
    "Para cada par genera un CSV en 3.Porcentaje adj dic con:\n",
    "    adjetivo_base, variantes, frecuencia, porcentaje\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# ── 1. Carpetas ────────────────────────────────────────────────────────────\n",
    "ROOT = Path(\"/home/ecoazul/alvaro/CORPUS/data/output/question1\")\n",
    "\n",
    "CSV_DIR   = ROOT / \"2.Adjetivos diccionario\"\n",
    "TXT_DIR   = ROOT / \"1.frases\"\n",
    "OUT_DIR   = ROOT / \"3.Porcentaje adj dic\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ── 2. Funciones auxiliares ────────────────────────────────────────────────\n",
    "def limpia(token: str) -> str:\n",
    "    \"\"\"Quita espacios y pasa a minúsculas.\"\"\"\n",
    "    return token.strip().lower()\n",
    "\n",
    "def construir_diccionarios(csv_path: Path):\n",
    "    \"\"\"Devuelve (variant_to_base, base_to_variants) a partir del CSV.\"\"\"\n",
    "    df = pd.read_csv(csv_path, sep=\";\", dtype=str).fillna(\"\")\n",
    "    variant_to_base = {}\n",
    "    base_to_variants = defaultdict(set)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        variants = [limpia(v) for v in row[\"adjective_variant\"].split(\",\") if limpia(v)]\n",
    "        bases    = [limpia(b) for b in row[\"adjective_base\"].split(\",\")   if limpia(b)]\n",
    "\n",
    "        if not variants and not bases:\n",
    "            continue\n",
    "\n",
    "        if len(variants) == len(bases) and bases:\n",
    "            pairs = zip(variants, bases)\n",
    "        elif len(bases) == 1:\n",
    "            pairs = [(v, bases[0]) for v in variants]\n",
    "        else:\n",
    "            bases_set = set(bases)\n",
    "            pairs = [(v, v) for v in variants if v in bases_set]\n",
    "\n",
    "        for v, b in pairs:\n",
    "            variant_to_base.setdefault(v, b)\n",
    "            if v != b:\n",
    "                base_to_variants[b].add(v)\n",
    "\n",
    "        for b in bases:\n",
    "            variant_to_base.setdefault(b, b)\n",
    "\n",
    "    return variant_to_base, base_to_variants\n",
    "\n",
    "def procesar_par(csv_path: Path, txt_path: Path, out_path: Path):\n",
    "    \"\"\"Genera el CSV de frecuencias/porcentaje para un par concreto.\"\"\"\n",
    "    variant_to_base, base_to_variants = construir_diccionarios(csv_path)\n",
    "\n",
    "    texto = txt_path.read_text(encoding=\"utf-8\").lower()\n",
    "    tokens = re.findall(r\"[a-záéíóúüñ]+\", texto, flags=re.IGNORECASE)\n",
    "    total_palabras = len(tokens)\n",
    "\n",
    "    frecuencia_base = defaultdict(int)\n",
    "    for tok in tokens:\n",
    "        base = variant_to_base.get(tok)\n",
    "        if base:\n",
    "            frecuencia_base[base] += 1\n",
    "\n",
    "    filas = []\n",
    "    for base, freq in sorted(frecuencia_base.items(), key=lambda x: x[1], reverse=True):\n",
    "        if freq == 0:\n",
    "            continue\n",
    "        variantes = \", \".join(sorted(base_to_variants[base]))\n",
    "        porcentaje = round(freq / total_palabras * 100, 2)\n",
    "        filas.append(\n",
    "            {\n",
    "            \"adjetivo_base\": base,\n",
    "            \"variantes\": variantes,\n",
    "            \"frecuencia\": freq,\n",
    "            \"porcentaje\": f\"{porcentaje}%\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    pd.DataFrame(filas).to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"[✓] {out_path.name} generado con {len(filas)} adjetivos (total {total_palabras} palabras)\")\n",
    "\n",
    "# ── 3. Bucle principal ─────────────────────────────────────────────────────\n",
    "for csv_file in CSV_DIR.glob(\"*_adjetivos.csv\"):\n",
    "    # Ej.: frases_01_ES_Cicloturismo_adjetivos.csv → base = frases_01_ES_Cicloturismo\n",
    "    base_name = csv_file.stem.replace(\"_adjetivos\", \"\")\n",
    "    txt_file  = TXT_DIR / f\"{base_name}.txt\"\n",
    "\n",
    "    if not txt_file.exists():\n",
    "        print(f\"[!] TXT no encontrado para {csv_file.name}, se omite.\")\n",
    "        continue\n",
    "\n",
    "    out_file = OUT_DIR / f\"{base_name}_adj_freq.csv\"\n",
    "    procesar_par(csv_file, txt_file, out_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodo IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "MODEL ='mistral-small:latest'\n",
    "\n",
    "frases_folder = \"/home/ecoazul/alvaro/CORPUS/data/output/question1/1.frases copy\"\n",
    "output_folder = \"/home/ecoazul/alvaro/CORPUS/data/output/question1/4.Adjetivos ia\"\n",
    "dic_folder = \"/home/ecoazul/alvaro/CORPUS/data/input/dic\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "frases_files = glob(os.path.join(frases_folder, \"frases_*.txt\"))\n",
    "\n",
    "for frases_path in tqdm(frases_files, desc=\"Procesando archivos\", position=0, leave=True):\n",
    "    with open(frases_path, encoding=\"utf-8\") as f:\n",
    "        split_sentences = [line.strip() for line in f if line.strip()]\n",
    "    lenguage = os.path.basename(frases_path).split(\"_\")[2].lower()\n",
    "    dic_path = os.path.join(dic_folder, f\"{lenguage}.adj\")\n",
    "    adjectives_map = load_adjective_dictionary(dic_path)\n",
    "    df = process_sentences_with_ollama(split_sentences, MODEL, lenguage, adjectives_map,max_retries=50)\n",
    "    output_csv = os.path.join(output_folder, os.path.basename(frases_path).replace(\".txt\", \"_ia.csv\"))\n",
    "    df.to_csv(output_csv, index=False, encoding=\"utf-8\", sep=\";\")\n",
    "    print(f\"Procesado y guardado: {output_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frecuency ia_variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "ROOT = Path(\"/home/ecoazul/alvaro/CORPUS/data/output/question1\")\n",
    "\n",
    "TXT_DIR   = ROOT / \"1.frases copy\"\n",
    "CSV_DIR   = ROOT / \"4.Adjetivos ia\"\n",
    "OUT_DIR = ROOT / \"5.porcentaje adj ia variant\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "frequencies = defaultdict(int)\n",
    "for csv_file in tqdm(CSV_DIR.glob(\"*ia.csv\"), desc=\"Procesando CSVs\"):\n",
    "    csv = pd.read_csv(csv_file, sep=\";\", dtype=str).fillna(\"\")\n",
    "    frequencies = defaultdict(int)\n",
    "    for _,fila in csv.iterrows():\n",
    "        for adj in fila[\"Adjectives_IA_variant\"].split(\",\"):\n",
    "            adjetivo = adj.strip().lower()\n",
    "            frequencies[adjetivo] += 1\n",
    "    # Guardar el resultado de frecuencias en un CSV\n",
    "    resultados = pd.DataFrame([\n",
    "        {\"adjetivo\": adj, \"frecuencia\": freq}\n",
    "        for adj, freq in frequencies.items() if adj and adj != \"none\"\n",
    "    ])\n",
    "    resultados = resultados.sort_values(by=\"frecuencia\", ascending=False)\n",
    "    output_csv = OUT_DIR / (csv_file.stem.replace(\"_ia\", \"\") + \"_adj_freq_ia.csv\")\n",
    "    resultados.to_csv(output_csv, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # Calcular el total de palabras en el texto original correspondiente\n",
    "    base_name = csv_file.stem.replace(\"_ia\", \"\")\n",
    "    txt_file = TXT_DIR / f\"{base_name}.txt\"\n",
    "    if txt_file.exists():\n",
    "        with open(txt_file, encoding=\"utf-8\") as f:\n",
    "            texto = f.read().lower()\n",
    "        tokens = re.findall(r\"[a-záéíóúüñ]+\", texto, flags=re.IGNORECASE)\n",
    "        total_palabras = len(tokens)\n",
    "        # Añadir columna de porcentaje\n",
    "        resultados[\"porcentaje\"] = round(resultados[\"frecuencia\"] / total_palabras * 100, 2).astype(str) + \"%\"\n",
    "        resultados.to_csv(output_csv, index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"Guardado: {output_csv}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Archivo de texto no encontrado: {txt_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frecuency ia base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Procesa TODOS los pares CSV/TXT de las carpetas:\n",
    "    2.Adjetivos diccionario   (CSV con _adjetivos.csv)\n",
    "    1.frases copy             (TXT completo)\n",
    "\n",
    "Para cada par genera un CSV en 3.Porcentaje adj dic con:\n",
    "    adjetivo_base, variantes, frecuencia, porcentaje\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# ── 1. Carpetas ────────────────────────────────────────────────────────────\n",
    "ROOT = Path(\"/home/ecoazul/alvaro/CORPUS/data/output/question1\")\n",
    "\n",
    "CSV_DIR   = ROOT / \"4.Adjetivos ia\"\n",
    "TXT_DIR   = ROOT / \"1.frases copy\"\n",
    "OUT_DIR   = ROOT / \"6.Porcentaje adj ia base\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ── 2. Funciones auxiliares ────────────────────────────────────────────────\n",
    "def limpia(token: str) -> str:\n",
    "    \"\"\"Quita espacios y pasa a minúsculas.\"\"\"\n",
    "    return token.strip().lower()\n",
    "\n",
    "def construir_diccionarios(csv_path: Path):\n",
    "    \"\"\"Devuelve (variant_to_base, base_to_variants) a partir del CSV.\"\"\"\n",
    "    df = pd.read_csv(csv_path, sep=\";\", dtype=str).fillna(\"\")\n",
    "    variant_to_base = {}\n",
    "    base_to_variants = defaultdict(set)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        variants = [limpia(v) for v in row[\"Adjectives_IA_variant\"].split(\",\") if limpia(v)]\n",
    "        bases    = [limpia(b) for b in row[\"Adjectives_IA_base\"].split(\",\")   if limpia(b)]\n",
    "\n",
    "        if not variants and not bases:\n",
    "            continue\n",
    "\n",
    "        if len(variants) == len(bases) and bases:\n",
    "            pairs = zip(variants, bases)\n",
    "        elif len(bases) == 1:\n",
    "            pairs = [(v, bases[0]) for v in variants]\n",
    "        else:\n",
    "            bases_set = set(bases)\n",
    "            pairs = [(v, v) for v in variants if v in bases_set]\n",
    "\n",
    "        for v, b in pairs:\n",
    "            variant_to_base.setdefault(v, b)\n",
    "            if v != b:\n",
    "                base_to_variants[b].add(v)\n",
    "\n",
    "        for b in bases:\n",
    "            variant_to_base.setdefault(b, b)\n",
    "\n",
    "    return variant_to_base, base_to_variants\n",
    "\n",
    "def procesar_par(csv_path: Path, txt_path: Path, out_path: Path):\n",
    "    \"\"\"Genera el CSV de frecuencias/porcentaje para un par concreto.\"\"\"\n",
    "    variant_to_base, base_to_variants = construir_diccionarios(csv_path)\n",
    "\n",
    "    texto = txt_path.read_text(encoding=\"utf-8\").lower()\n",
    "    tokens = re.findall(r\"[a-záéíóúüñ]+\", texto, flags=re.IGNORECASE)\n",
    "    total_palabras = len(tokens)\n",
    "\n",
    "    frecuencia_base = defaultdict(int)\n",
    "    for tok in tokens:\n",
    "        base = variant_to_base.get(tok)\n",
    "        if base:\n",
    "            frecuencia_base[base] += 1\n",
    "\n",
    "    filas = []\n",
    "    for base, freq in sorted(frecuencia_base.items(), key=lambda x: x[1], reverse=True):\n",
    "        if freq == 0:\n",
    "            continue\n",
    "        variantes = \", \".join(sorted(base_to_variants[base]))\n",
    "        porcentaje = round(freq / total_palabras * 100, 2)\n",
    "        filas.append(\n",
    "            {\n",
    "            \"adjetivo_base\": base,\n",
    "            \"variantes\": variantes,\n",
    "            \"frecuencia\": freq,\n",
    "            \"porcentaje\": f\"{porcentaje}%\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    pd.DataFrame(filas).to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"[✓] {out_path.name} generado con {len(filas)} adjetivos (total {total_palabras} palabras)\")\n",
    "\n",
    "# ── 3. Bucle principal ─────────────────────────────────────────────────────\n",
    "for csv_file in CSV_DIR.glob(\"*_ia.csv\"):\n",
    "    # Ej.: frases_01_ES_Cicloturismo_adjetivos.csv → base = frases_01_ES_Cicloturismo\n",
    "    base_name = csv_file.stem.replace(\"_ia\", \"\")\n",
    "    txt_file  = TXT_DIR / f\"{base_name}.txt\"\n",
    "\n",
    "    if not txt_file.exists():\n",
    "        print(f\"[!] TXT no encontrado para {csv_file.name}, se omite.\")\n",
    "        continue\n",
    "\n",
    "    out_file = OUT_DIR / f\"{base_name}_adj_freq_ia_base.csv\"\n",
    "    procesar_par(csv_file, txt_file, out_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def comparar_adjetivos(row):\n",
    "    # Lee los dos campos, trata NaN como cadena vacía\n",
    "    val1 = \"\" if pd.isna(row[\"adjective_base\"])       else str(row[\"adjective_base\"])\n",
    "    val2 = \"\" if pd.isna(row[\"Adjectives_IA_base\"])   else str(row[\"Adjectives_IA_base\"])\n",
    "    \n",
    "    # Divide, quita espacios y filtra los indeseables\n",
    "    filtro = lambda w: w and w.lower() not in (\"none\", \"nan\")\n",
    "    set1 = {w.strip() for w in val1.split(\",\") if filtro(w.strip())}\n",
    "    set2 = {w.strip() for w in val2.split(\",\") if filtro(w.strip())}\n",
    "    \n",
    "    # Si ambos están vacíos, no pongas nada\n",
    "    if not set1 and not set2:\n",
    "        return \"\"\n",
    "    \n",
    "    # Calcula comunes y no comunes\n",
    "    comunes   = sorted(set1 & set2)\n",
    "    solo_dic  = sorted(set1 - set2)\n",
    "    solo_ia   = sorted(set2 - set1)\n",
    "    \n",
    "    # Junta solo las partes no vacías, separadas por coma\n",
    "    partes = []\n",
    "    if comunes:   partes.append(\", \".join(comunes))\n",
    "    if solo_dic:  partes.append(\", \".join(solo_dic))\n",
    "    if solo_ia:   partes.append(\", \".join(solo_ia))\n",
    "    \n",
    "    return \", \".join(partes)\n",
    "\n",
    "union_folder = \"/home/ecoazul/alvaro/CORPUS/data/output/question1/7.union\"\n",
    "os.makedirs(union_folder, exist_ok=True)\n",
    "\n",
    "diccionario_folder = \"/home/ecoazul/alvaro/CORPUS/data/output/question1/2.Adjetivos diccionario\"\n",
    "ia_folder         = \"/home/ecoazul/alvaro/CORPUS/data/output/question1/4.Adjetivos ia\"\n",
    "\n",
    "diccionario_files = sorted(f for f in os.listdir(diccionario_folder) if f.endswith(\"_adjetivos.csv\"))\n",
    "ia_files         = sorted(f for f in os.listdir(ia_folder)       if f.endswith(\"_ia.csv\"))\n",
    "\n",
    "for dic_file, ia_file in zip(diccionario_files, ia_files):\n",
    "    df_dic = pd.read_csv(os.path.join(diccionario_folder, dic_file),\n",
    "                         sep=\";\", encoding=\"utf-8\")\n",
    "    df_ia  = pd.read_csv(os.path.join(ia_folder, ia_file),\n",
    "                         sep=\";\", encoding=\"utf-8\")\n",
    "\n",
    "    if \"sentence\" in df_dic.columns and \"sentence\" in df_ia.columns:\n",
    "        df_union = df_dic.merge(\n",
    "            df_ia[[\"sentence\", \"Adjectives_IA_base\"]],\n",
    "            on=\"sentence\", how=\"inner\"\n",
    "        )[\n",
    "            [\"sentence\", \"adjective_base\", \"Adjectives_IA_base\"]\n",
    "        ]\n",
    "\n",
    "        # Aplica la función ya limpia de valores vacíos\n",
    "        df_union[\"adjectives\"] = df_union.apply(comparar_adjetivos, axis=1)\n",
    "\n",
    "        output_path = os.path.join(\n",
    "            union_folder,\n",
    "            dic_file.replace(\"_adjetivos.csv\", \"_union.csv\")\n",
    "        )\n",
    "        df_union.to_csv(output_path, index=False, encoding=\"utf-8\", sep=\";\")\n",
    "    else:\n",
    "        print(f\"Column 'sentence' not found in: {dic_file}, {ia_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 2. Listado adjetivos-sustantivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing adjectives: 100%|██████████| 106/106 [00:31<00:00,  3.40it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "MODEL = 'mistral-small:latest'\n",
    "input_folder = '/home/ecoazul/alvaro/CORPUS/data/output/question1/7.union'\n",
    "output_folder = '/home/ecoazul/alvaro/CORPUS/data/output/question2/1.adjetivos_sustantivos'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith('.csv'):\n",
    "        input_csv = os.path.join(input_folder, filename)\n",
    "        output_file = os.path.join(output_folder, filename.replace('.csv', '.xlsx'))\n",
    "        df = pd.read_csv(input_csv, sep=';')\n",
    "        result_df = process_nouns(df, model=MODEL, output_file=output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adj_to_sentence = pd.read_csv('/home/ecoazul/alvaro/CORPUS/data/output/question2/1.adjetivos_sustantivos/frases_01_ES_Cicloturismo_union.xlsx', sep=';')\n",
    "# Suponiendo que ya tienes el DataFrame 'df'\n",
    "agrupado = df_adj_to_sentence.groupby('adjective')['noun'].apply(lambda x: ', '.join(x.unique())).reset_index()\n",
    "\n",
    "# Crear una nueva columna con el conteo de sustantivos\n",
    "agrupado['Conteo'] = agrupado['noun'].apply(lambda x: len(x.split(', ')))\n",
    "\n",
    "# Ordenar el DataFrame según el conteo de sustantivos de forma descendente (o ascendente si lo prefieres)\n",
    "agrupado = agrupado.sort_values(by='Conteo', ascending=False)\n",
    "\n",
    "# Guardar el resultado en un CSV en la ruta especificada\n",
    "agrupado.to_csv('/home/ecoazul/alvaro/CORPUS/data/output/question2/conteo.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 3. Porcentaje de colores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagenes a PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm \n",
    "\n",
    "input_folder = \"/home/ecoazul/alvaro/CORPUS/data/input/corpus\"\n",
    "output_folder = \"/home/ecoazul/alvaro/CORPUS/data/output/question3/1.pdf_complete_to_images\"\n",
    "\n",
    "for filename in tqdm(os.listdir(input_folder),desc=\"Procesando PDFs\"):\n",
    "    if filename.lower().endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(input_folder, filename)\n",
    "        # Crear carpeta específica para cada PDF (sin extensión)\n",
    "        pdf_name = os.path.splitext(filename)[0]\n",
    "        pdf_output_folder = os.path.join(output_folder, pdf_name)\n",
    "        os.makedirs(pdf_output_folder, exist_ok=True)\n",
    "        print(f\"Procesando: {pdf_path} -> {pdf_output_folder}\")\n",
    "        total_pages = convert_pdf_to_images(pdf_path, pdf_output_folder)\n",
    "        print(f\"{filename}: {total_pages} páginas convertidas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis por paginas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rutas de entrada y salida\n",
    "input_folder = \"/home/ecoazul/alvaro/CORPUS/data/output/question3/1.pdf_complete_to_images\"\n",
    "output_folder = \"/home/ecoazul/alvaro/CORPUS/data/output/question3/2.analisis_por_paginas\"\n",
    "num_colors = 10\n",
    "\n",
    "process_folder(input_folder, output_folder, num_colors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Analisis completo - miniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando PDFs completos:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "01_ES_Cicloturismo: Detectadas 1 páginas para extracción de color dominante.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adjusting MiniBatchKMeans: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s]\n",
      "Calculating overall percentages: 100%|██████████| 1/1 [00:00<00:00, 10.94it/s]\n",
      "Procesando PDFs completos: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF generado: /home/ecoazul/alvaro/CORPUS/data/output/question3/3.analisis_completo/01_ES_Cicloturismo/overall_dominant_colors.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"/home/ecoazul/alvaro/CORPUS/data/output/question3/1.pdf_complete_to_images\"\n",
    "output_folder = \"/home/ecoazul/alvaro/CORPUS/data/output/question3/3.analisis_completo\"\n",
    "num_colors = 5\n",
    "\n",
    "complete_analysis(input_folder, output_folder, num_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 4. Analisis de imagenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraccion de imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_corpus import *\n",
    "import os\n",
    "\n",
    "input_folder = \"/home/ecoazul/alvaro/CORPUS/data/input/corpus\"\n",
    "output_base_folder = \"/home/ecoazul/alvaro/CORPUS/data/output/question4/1.images_from_pdf\"\n",
    "\n",
    "os.makedirs(output_base_folder, exist_ok=True)\n",
    "\n",
    "for filename in tqdm(os.listdir(input_folder),desc=\"Obteniendo imagenes de PDFs\"):\n",
    "    if filename.lower().endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(input_folder, filename)\n",
    "        pdf_name = os.path.splitext(filename)[0]\n",
    "        output_folder = os.path.join(output_base_folder, pdf_name)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        images = extract_images_from_pdf(pdf_path, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos Captions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLIP-2 + Flan-T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:26<00:00,  5.29s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Procesando imágenes: 100%|██████████| 2/2 [09:23<00:00, 281.57s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "input_folder = '/home/ecoazul/alvaro/CORPUS/data/output/question4/1.images_from_pdf'\n",
    "output_base = '/home/ecoazul/alvaro/CORPUS/data/output/question4/2.description'\n",
    "model_name = \"Salesforce/instructblip-flan-t5-xxl\"\n",
    "\n",
    "# Cargar modelo y procesador\n",
    "processor, model, device = load_model_instruct(model_name)\n",
    "\n",
    "os.makedirs(output_base, exist_ok=True)\n",
    "for root, dirs, files in os.walk(input_folder):\n",
    "    image_files = [os.path.join(root, f) for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    if not image_files:\n",
    "        continue\n",
    "\n",
    "    # Nombre base para el CSV (usa solo el nombre de la carpeta relativa)\n",
    "    folder_name = os.path.relpath(root, input_folder)\n",
    "    output_csv = os.path.join(output_base, f\"{folder_name.replace(os.sep, '_')}_description.csv\")\n",
    "    results = process_images_in_folder(root, processor, model, device, output_csv)\n",
    "    save_results_to_csv(results, output_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento IA Generativa - elementos imagenes(desde descripcion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando descripciones: 100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_folder = '/home/ecoazul/alvaro/CORPUS/data/output/question4/2.description'\n",
    "output_folder = '/home/ecoazul/alvaro/CORPUS/data/output/question4/3.elementos'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "MODEL = 'mistral-small:latest'\n",
    "\n",
    "for filename in tqdm(os.listdir(input_folder),desc=\"Procesando descripciones\"):\n",
    "    if filename.endswith('.csv'):\n",
    "        input_csv = os.path.join(input_folder, filename)\n",
    "        df = pd.read_csv(input_csv)\n",
    "        df['elementos'] = df['Description'].apply(lambda s: process_description(s, MODEL))\n",
    "        output_csv = os.path.join(output_folder, filename)\n",
    "        df.to_csv(output_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conteo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: /home/ecoazul/alvaro/CORPUS/data/output/question4/4.conteo/01_ES_Cicloturismo_description.docx\n"
     ]
    }
   ],
   "source": [
    "process_folder_elem(\n",
    "    '/home/ecoazul/alvaro/CORPUS/data/output/question4/3.elementos',\n",
    "    '/home/ecoazul/alvaro/CORPUS/data/output/question4/4.conteo',\n",
    "    column_name='elementos'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
